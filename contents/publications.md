# Projects

## Neural Feature Fields for Language-Based Dexterous Robotic Manipulation 

<img src="../static/assets/img/hithand.gif" alt="DexF3RM" width="200"> 

Image models trained with self-supervision and language supervision possess extensive world knowledge, yet they often fall short in providing the detailed 3D understanding necessary for robotic tasks. This research combines precise 3D geometry with rich semantic information from 2D foundation models, enabling few-shot learning for 6-DOF grasping with a dexterous hand.

* Code (available soon)
* Thesis (available soon)


## DexGANGrasp: Dexterous Generative Adversarial Grasping Synthesis for Task-Oriented Manipulation

<img src="../static/assets/img/tog.gif" alt="DexGANGrasp" width="300">

DexGanGrasp is an AI model that uses cGANs to generate and evaluate robot grasps, achieving higher success rates than previous methods. By incorporating LLMs and VLMs through DexAfford-Prompt, it enables task-oriented grasping for more complex, real-world scenarios.

* [Website](https://david-s-martinez.github.io/DexGANGrasp.io/)
* [Video](https://youtu.be/egQaemeAy5k)
* [Paper](https://www.arxiv.org/abs/2407.17348)


## Universal Robotic Cell

<img src="../static/assets/img/obj_detect.gif" alt="Universal Robotic Cell" width="200">

An industrial robotic cell powered by Deep Learning and 3D Computer Vision to detect, track, optimally grasp and sort moving objects with complex geometries on a conveyor belt. Our developed pick and place architecture allows an industrial KUKA robot to be easily integrated with 3D computer vision methods and state of the art instance segmentation algorithms such as YOLACT for object detection. We showcase our solution on packets of different colors and sizes and contents.

* [Code](https://github.com/testbedCIIRC/Robot-Vision-PickPlace)
* [Video](https://www.youtube.com/watch?v=R7c1MT30IrA)
* [Paper](https://ieeexplore.ieee.org/document/10260601)
* [Article](https://testbed.ciirc.cvut.cz/labs/testbed/robotic-cells-ai-machine-vision)


## 5G Edge Vision System

<img src="../static/assets/img/plane_detection_demo.gif" alt="5G Edge Vision System" width="300">

An artificial vision system based on CNNs and 3D pose estimation for a collaborative delta robot using an internal campus 5G network and a GPU server. The project was sponsored by T-Mobile CZ (Deutsche Telekom) and Siemens.

* [Code](https://github.com/david-s-martinez/Deep-Vision-System-with-5G-Edge-GPU-Server)
* [Article](https://testbed.ciirc.cvut.cz/labs/testbed/flexlink-delta/)


## Luggage Carrying Task with the TIAGo Humanoid Robotic Platform

<img src="../static/assets/img/tiago.gif" alt="Luggage Carrying Task with the TIAGo Humanoid Robotic Platform" width="300">

Integration of advanced robotic capabilities such as perception, manipulation, navigation, and human-robot interaction using ROS. Key achievements include autonomous detection and navigation to pick up luggage (bag) based on CNNs, obstacle avoidance via SLAM, and following the operator to a designated location based on Human-Robot Interaction.

* [Code](https://github.com/david-s-martinez/tiago_ws)
* [Video](https://www.youtube.com/watch?v=Ih3iIqwa0Ek)
* [Article](http://dx.doi.org/10.13140/RG.2.2.32927.88485)


## NAO U NO: Teaching the NAO Humanoid to Play UNO Using AI

<img src="../static/assets/img/nao.gif" alt="NAO U NO: Teaching the NAO Humanoid to Play UNO Using AI" width="300">

The project aims to make the NAO Robot play the UNO card game. It uses ROS to integrate its different assets like sensing, deep learning based card detection, bipedal locomotion and decision-making based on a State Machine Agent.

* [Code](https://github.com/david-s-martinez/Nao_ws)
* [Video](https://www.youtube.com/watch?v=_0Dh0V_dilE)
* [Article](http://dx.doi.org/10.13140/RG.2.2.19506.11201)


## Convolutional Neural Network Based Soft-Exoskeleton for Stroke Patient Rehabilitation

<img src="../static/assets/img/soft_exo.gif" alt="Convolutional Neural Network Based Soft-Exoskeleton for Stroke Patient Rehabilitation" width="300">

This paper presents a soft robotic glove for stroke patients that incorporates a CNN-based computer vision system. This neural network allows the glove to intelligently recognize objects and automatically adjust the hand's opening for grasping.

* [Code](https://github.com/david-s-martinez/CNN-based-soft-exoskeleton)
* [Article](http://dx.doi.org/10.13140/RG.2.2.18303.52644)


## Design and implementation of 2-DoF upper-limb exoskeleton with combined force and position control for rehabilitation

<img src="../static/assets/img/exo_skin.gif" alt="Design and implementation of 2-DoF upper-limb exoskeleton with combined force and position control for rehabilitation" width="300">

The exoskeleton assists arm and wrist movements with both position and force control, and uses an "intention detection algorithm" to predict the user's desired motions. This allows for more natural and responsive assistance, which was evaluated by measuring muscle activity and tracking the accuracy of executed movements.

* [Code](https://github.com/david-s-martinez/Wearable-Robotics)
* [Article](http://dx.doi.org/10.13140/RG.2.2.25014.41289)


## Control System of a Lower-Extremity Exoskeleton Based on Artificial Neural Networks

<img src="../static/assets/img/leg_exo.gif" alt="Control System of a Lower-Extremity Exoskeleton Based on Artificial Neural Networks" width="300">

Design and implementation of a functional prototype of lower extremity brace actuation and its wireless communication control system. The design provides supportive torque and increases the range of motion after complications reducing muscular strength. The control system prototype facilitates elevating a leg, gradually followed by standing and slow walking. The main control modalities are based on an Artificial Neural Network (ANN). 

* [Code](https://github.com/david-s-martinez/Exoskeleton-Control-Algorithms)
* [Video](https://youtu.be/UmKADVIlhPU?si=6DHJGQz-yny-Oeq1&t=19)
* [Article](https://www.researchgate.net/publication/346463112_Control_System_of_a_Lower-Extremity_Exoskeleton_Based_on_Artificial_Neural_Networks)


## Adversarial Multi-Agent Training Based on Deep Q-Learning Applied to the Snake Game

<img src="../static/assets/img/snake.gif" alt="Adversarial Multi-Agent Training Based on Deep Q-Learning Applied to the Snake Game" width="300">

* [Code](https://github.com/david-s-martinez/reinforcement-learning-game)
* [Poster](http://dx.doi.org/10.13140/RG.2.2.35504.26885)


## Fabrication of Soft Milli, Micro and Nano Robots Based on Alginate Polymer Coating and Encapsulation

<!-- ![Fabrication of Soft Milli, Micro and Nano Robots Based on Alginate Polymer Coating and Encapsulation](../static/assets/img/chip.jpg) -->

<img src="../static/assets/img/chip.jpg" alt="Fabrication of Soft Milli, Micro and Nano Robots Based on Alginate Polymer Coating and Encapsulation" width="300">

* [Article](http://dx.doi.org/10.13140/RG.2.2.35919.60328)

<!-- <!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=0.75, minimum-scale=0.2, maximum-scale=3, user-scalable=yes" />
    <title>Projects</title>
    <style>
        body {
            /* font-family: Arial, sans-serif; */
            line-height: 1.6;
            margin: 20px;
        }
        .project {
            display: flex;
            flex-direction: row-reverse;
            align-items: center;
            margin-bottom: 40px;
        }
        .project img {
            width: 300px;
            height: auto;
            margin-left: 20px;
        }
        .project-content {
            flex: 1;
            text-align: left;
        }
        h3 {
            margin-bottom: 10px;
        }
        .links {
            margin-top: 10px;
        }
        .links a {
            margin-right: 10px;
            text-decoration: none;
            color: #007BFF;
        }
        .links a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>

<div class="project">
    <img src="../static/assets/img/hithand.gif" alt="DexF3RM">
    <div class="project-content">
        <h3>Neural Feature Fields for Language-Based Dexterous Robotic Manipulation</h3>
        <p>Image models trained with self-supervision and language supervision possess extensive world knowledge, yet they often fall short in providing the detailed 3D understanding necessary for robotic tasks. This research combines precise 3D geometry with rich semantic information from 2D models foundation, enabling few-shot learning for 6-DOF grasping with a dexterous hand.</p>
        <div class="links">
            <a href="">Code (available soon)</a>
            <a href="">Thesis (available soon)</a>
        </div>
    </div>
</div>
<div class="project">
    <img src="../static/assets/img/tog.gif" alt="DexGANGrasp">
    <div class="project-content">
        <h3>DexGANGrasp: Dexterous Generative Adversarial Grasping Synthesis for Task-Oriented Manipulation</h3>
        <p>DexGanGrasp is an AI model that uses cGANs to generate and evaluate robot grasps, achieving higher success rates than previous methods. By incorporating LLMs and VLMs through DexAfford-Prompt, it enables task-oriented grasping for more complex, real-world scenarios.</p>
        <div class="links">
            <a href="https://david-s-martinez.github.io/DexGANGrasp.io/">Website</a>
            <a href="https://youtu.be/egQaemeAy5k">Video</a>
            <a href="https://www.arxiv.org/abs/2407.17348">Paper</a>
        </div>
    </div>
</div>

<div class="project">
    <img src="../static/assets/img/obj_detect.gif" alt="Universal Robotic Cell">
    <div class="project-content">
        <h3>Universal Robotic Cell</h3>
        <p>An industrial robotic cell powered by Deep Learning and 3D Computer Vision to detect, track, optimally grasp and sort moving objects with complex geometries on a conveyor belt. Our developed pick and place architecture allows an industrial KUKA robot to be easily integrated with 3D computer vision methods and state of the art instance segmentation algorithms such as YOLACT for object detection. We showcase our solution on packets of different colors and sizes and contents.</p>
        <div class="links">
            <a href="https://github.com/testbedCIIRC/Robot-Vision-PickPlace">Code</a>
            <a href="https://www.youtube.com/watch?v=R7c1MT30IrA">Video</a>
            <a href="https://ieeexplore.ieee.org/document/10260601">Paper</a>
            <a href="https://testbed.ciirc.cvut.cz/labs/testbed/robotic-cells-ai-machine-vision">Article</a>
        </div>
    </div>
</div>

<div class="project">
    <img src="../static/assets/img/plane_detection_demo.gif" alt="5G Edge Vision System">
    <div class="project-content">
        <h3>5G Edge Vision System</h3>
        <p>An artificial vision system based on CNNs and 3D pose estimation for a collaborative delta robot using an internal campus 5G network and a GPU server. The project was sponsored by T-Mobile CZ (Deutsche Telekom) and Siemens.</p>
        <div class="links">
            <a href="https://github.com/david-s-martinez/Deep-Vision-System-with-5G-Edge-GPU-Server">Code</a>
            <a href="https://testbed.ciirc.cvut.cz/labs/testbed/flexlink-delta/">Article</a>
        </div>
    </div>
</div>

<div class="project">
    <img src="../static/assets/img/tiago.gif" alt="Luggage Carrying Task with the TIAGo Humanoid Robotic Platform">
    <div class="project-content">
        <h3>Luggage Carrying Task with the TIAGo Humanoid Robotic Platform</h3>
        <p>Integration of advanced robotic capabilities such as perception, manipulation, navigation, and human-robot interaction using ROS. Key achievements include autonomous detection and navigation to pick up luggage (bag) based on CNNs, obstacle avoidance via SLAM, and following the operator to a designated location based on Human-Robot Interaction.</p>
        <div class="links">
            <a href="https://github.com/david-s-martinez/tiago_ws">Code</a>
            <a href="https://www.youtube.com/watch?v=Ih3iIqwa0Ek">Video</a>
            <a href="http://dx.doi.org/10.13140/RG.2.2.32927.88485">Article</a>
        </div>
    </div>
</div>

<div class="project">
    <img src="../static/assets/img/nao.gif" alt="NAO U NO: Teaching the NAO Humanoid to Play UNO Using AI">
    <div class="project-content">
        <h3>NAO U NO: Teaching the NAO Humanoid to Play UNO Using AI</h3>
        <p>The project aims to make the NAO Robot play the UNO card game. It uses ROS to integrate its different assets like sensing, deep learning based card detection, bipedal locomotion and decision-making based on a State Machine Agent.</p>
        <div class="links">
            <a href="https://github.com/david-s-martinez/Nao_ws">Code</a>
            <a href="https://www.youtube.com/watch?v=_0Dh0V_dilE">Video</a>
            <a href="http://dx.doi.org/10.13140/RG.2.2.19506.11201">Article</a>
        </div>
    </div>
</div>

<div class="project">
    <img src="../static/assets/img/soft_exo.gif" alt="Convolutional Neural Network Based Soft-Exoskeleton for Stroke Patient Rehabilitation">
    <div class="project-content">
        <h3>Convolutional Neural Network Based Soft-Exoskeleton for Stroke Patient Rehabilitation</h3>
        <p>This paper presents a soft robotic glove for stroke patients that incorporates a CNN-based computer vision system. This neural network allows the glove to intelligently recognize objects and automatically adjust the hand's opening for grasping.</p>
        <div class="links">
            <a href="https://github.com/david-s-martinez/CNN-based-soft-exoskeleton">Code</a>
            <a href="http://dx.doi.org/10.13140/RG.2.2.18303.52644">Article</a>
        </div>
    </div>
</div>

<div class="project">
    <img src="../static/assets/img/exo_skin.gif" alt="Design and implementation of 2-DoF upper-limb exoskeleton with combined force and position control for rehabilitation">
    <div class="project-content">
        <h3>Design and implementation of 2-DoF upper-limb exoskeleton with combined force and position control for rehabilitation</h3>
        <p>The exoskeleton assists arm and wrist movements with both position and force control, and uses an "intention detection algorithm" to predict the user's desired motions. This allows for more natural and responsive assistance, which was evaluated by measuring muscle activity and tracking the accuracy of executed movements.</p>
        <div class="links">
            <a href="https://github.com/david-s-martinez/Wearable-Robotics">Code</a>
            <a href="http://dx.doi.org/10.13140/RG.2.2.25014.41289">Article</a>
        </div>
    </div>
</div>

<div class="project">
    <img src="../static/assets/img/leg_exo.gif" alt="Control System of a Lower-Extremity Exoskeleton Based on Artificial Neural Networks">
    <div class="project-content">
        <h3>Control System of a Lower-Extremity Exoskeleton Based on Artificial Neural Networks</h3>
        <p>Design and implementation of a functional prototype of lower extremity brace actuation and its wireless communication control system. The design provides supportive torque and increases the range of motion after complications reducing muscular strength. The control system prototype facilitates elevating a leg, gradually followed by standing and slow walking. The main control modalities are based on an Artificial Neural Network (ANN). </p>
        <div class="links">
            <a href="https://github.com/david-s-martinez/Exoskeleton-Control-Algorithms">Code</a>
            <a href="https://youtu.be/UmKADVIlhPU?si=6DHJGQz-yny-Oeq1&t=19">Video</a>
            <a href="https://www.researchgate.net/publication/346463112_Control_System_of_a_Lower-Extremity_Exoskeleton_Based_on_Artificial_Neural_Networks">Article</a>
        </div>
    </div>
</div>

<div class="project">
    <img src="../static/assets/img/snake.gif" alt="Adversarial Multi-Agent Training Based on Deep Q-Learning Applied to the Snake Game">
    <div class="project-content">
        <h3>Adversarial Multi-Agent Training Based on Deep Q-Learning Applied to the Snake Game</h3>
        <div class="links">
            <a href="https://github.com/david-s-martinez/reinforcement-learning-game">Code</a>
            <a href="http://dx.doi.org/10.13140/RG.2.2.35504.26885">Poster</a>
        </div>
    </div>
</div>

<div class="project">
    <img src="../static/assets/img/chip.jpg" alt="Fabrication of Soft Milli, Micro and Nano Robots Based on Alginate Polymer Coating and Encapsulation">
    <div class="project-content">
        <h3>Fabrication of Soft Milli, Micro and Nano Robots Based on Alginate Polymer Coating and Encapsulation</h3>
        <div class="links">
            <a href="http://dx.doi.org/10.13140/RG.2.2.35919.60328">Article</a>
        </div>
    </div>
</div>

</body>
</html> -->
